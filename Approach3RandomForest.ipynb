{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, matthews_corrcoef\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_train():\n",
    "    \n",
    "    #Initialize the Training Sets\n",
    "    df_train1 = pd.read_csv('Training Sets/train1_aac.csv')\n",
    "    df_train2 = pd.read_csv('Training Sets/train2_aac.csv')\n",
    "    df_train3 = pd.read_csv('Training Sets/train3_aac.csv')\n",
    "    df_train4 = pd.read_csv('Training Sets/train4_aac.csv')\n",
    "    df_train5 = pd.read_csv('Training Sets/train5_aac.csv')\n",
    "    \n",
    "    x_train1 = df_train1.iloc[:, 0:-1].values\n",
    "    x_train2 = df_train2.iloc[:, 0:-1].values\n",
    "    x_train3 = df_train3.iloc[:, 0:-1].values\n",
    "    x_train4 = df_train4.iloc[:, 0:-1].values\n",
    "    x_train5 = df_train5.iloc[:, 0:-1].values\n",
    "    \n",
    "    y_train1 = df_train1.iloc[:, -1].values\n",
    "    y_train2 = df_train2.iloc[:, -1].values\n",
    "    y_train3 = df_train3.iloc[:, -1].values\n",
    "    y_train4 = df_train4.iloc[:, -1].values\n",
    "    y_train5 = df_train5.iloc[:, -1].values\n",
    "    \n",
    "    return (x_train1, x_train2, x_train3, x_train4, x_train5, y_train1, y_train2, y_train3, y_train4, y_train5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_test():\n",
    "    \n",
    "    #Initialize the Test Sets\n",
    "    df_test1 = pd.read_csv('Testing Sets/test1_aac.csv')\n",
    "    df_test2 = pd.read_csv('Testing Sets/test2_aac.csv')\n",
    "    df_test3 = pd.read_csv('Testing Sets/test3_aac.csv')\n",
    "    df_test4 = pd.read_csv('Testing Sets/test4_aac.csv')\n",
    "    df_test5 = pd.read_csv('Testing Sets/test5_aac.csv')\n",
    "    \n",
    "    x_test1 = df_test1.iloc[:, 0:-1].values\n",
    "    x_test2 = df_test2.iloc[:, 0:-1].values\n",
    "    x_test3 = df_test3.iloc[:, 0:-1].values\n",
    "    x_test4 = df_test4.iloc[:, 0:-1].values\n",
    "    x_test5 = df_test5.iloc[:, 0:-1].values\n",
    "    \n",
    "    y_test1 = df_test1.iloc[:, -1].values\n",
    "    y_test2 = df_test2.iloc[:, -1].values\n",
    "    y_test3 = df_test3.iloc[:, -1].values\n",
    "    y_test4 = df_test4.iloc[:, -1].values\n",
    "    y_test5 = df_test5.iloc[:, -1].values\n",
    "    \n",
    "    return (x_test1, x_test2, x_test3, x_test4, x_test5, y_test1, y_test2, y_test3, y_test4, y_test5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_actual_pred():\n",
    "    all_actual_predictions = pd.DataFrame()\n",
    "    \n",
    "    #Converting into DataFrames\n",
    "    y_test1_df = pd.DataFrame(y_test1)\n",
    "    y_test2_df = pd.DataFrame(y_test2)\n",
    "    y_test3_df = pd.DataFrame(y_test3)\n",
    "    y_test4_df = pd.DataFrame(y_test4)\n",
    "    y_test5_df = pd.DataFrame(y_test5)\n",
    "    \n",
    "    all_actual_predictions = all_actual_predictions.append(y_test1_df, ignore_index = True)\n",
    "    all_actual_predictions = all_actual_predictions.append(y_test2_df, ignore_index = True)\n",
    "    all_actual_predictions = all_actual_predictions.append(y_test3_df, ignore_index = True)\n",
    "    all_actual_predictions = all_actual_predictions.append(y_test4_df, ignore_index = True)\n",
    "    all_actual_predictions = all_actual_predictions.append(y_test5_df, ignore_index = True)\n",
    "    \n",
    "    return all_actual_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on Set 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1, x_train2, x_train3, x_train4, x_train5, y_train1, y_train2, y_train3, y_train4, y_train5 = initialize_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test1, x_test2, x_test3, x_test4, x_test5, y_test1, y_test2, y_test3, y_test4, y_test5 = initialize_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_estimators':[10,20,30,40,50,60,70,80,90,100], 'max_depth':[10,20,50,100], 'criterion':('gini', 'entropy'), 'min_samples_split' : [10,20,30,40,50], 'max_features': ('auto', 'sqrt', 'log2')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raman/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_sco...lse,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'criterion': ('gini', 'entropy'),\n",
       "                         'max_depth': [10, 20, 50, 100],\n",
       "                         'max_features': ('auto', 'sqrt', 'log2'),\n",
       "                         'min_samples_split': [10, 20, 30, 40, 50],\n",
       "                         'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90,\n",
       "                                          100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4 = GridSearchCV(RandomForestClassifier(), parameters)\n",
    "clf4.fit(x_train4, y_train4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 100,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_split': 40,\n",
       " 'n_estimators': 30}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_rf4 = clf4.best_params_\n",
    "best_params_rf4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred4 = clf4.predict(x_test4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred4_df = pd.DataFrame(y_pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training with same params on set 1\n",
    "clf1 = RandomForestClassifier(n_estimators=30, min_samples_split=40, max_features='auto', max_depth=100, criterion='entropy')\n",
    "clf1.fit(x_train1, y_train1)\n",
    "y_pred1 = clf1.predict(x_test1)\n",
    "y_pred1_df = pd.DataFrame(y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training with same params on set 2\n",
    "clf2 = RandomForestClassifier(n_estimators=30, min_samples_split=40, max_features='auto', max_depth=100, criterion='entropy')\n",
    "clf2.fit(x_train2, y_train2)\n",
    "y_pred2 = clf1.predict(x_test2)\n",
    "y_pred2_df = pd.DataFrame(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training with same params on set 3\n",
    "clf3 = RandomForestClassifier(n_estimators=30, min_samples_split=40, max_features='auto', max_depth=100, criterion='entropy')\n",
    "clf3.fit(x_train3, y_train3)\n",
    "y_pred3 = clf3.predict(x_test3)\n",
    "y_pred3_df = pd.DataFrame(y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training with same params on set 5\n",
    "clf5 = RandomForestClassifier(n_estimators=30, min_samples_split=40, max_features='auto', max_depth=100, criterion='entropy')\n",
    "clf5.fit(x_train5, y_train5)\n",
    "y_pred5 = clf5.predict(x_test5)\n",
    "y_pred5_df = pd.DataFrame(y_pred5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_params4 = pd.DataFrame()\n",
    "y_pred_params4 = y_pred_params4.append(y_pred1_df, ignore_index = True)\n",
    "y_pred_params4 = y_pred_params4.append(y_pred2_df, ignore_index = True)\n",
    "y_pred_params4 = y_pred_params4.append(y_pred3_df, ignore_index = True)\n",
    "y_pred_params4 = y_pred_params4.append(y_pred4_df, ignore_index = True)\n",
    "y_pred_params4 = y_pred_params4.append(y_pred5_df, ignore_index = True)\n",
    "y_pred_params4.to_csv('Results/Overall Acc 4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('Results/Random Forest/Overall Acc 1.csv')\n",
    "df2 = pd.read_csv('Results/Random Forest/Overall Acc 2.csv')\n",
    "df3 = pd.read_csv('Results/Random Forest/Overall Acc 3.csv')\n",
    "df4 = pd.read_csv('Results/Random Forest/Overall Acc 4.csv')\n",
    "df5 = pd.read_csv('Results/Random Forest/Overall Acc 5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_pred_df = all_actual_pred()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16120"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(df1) + len(df2) + len(df3) + len(df4) + len(df5)\n",
    "len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16120"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actual_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16120"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Calculating Accuracies\n",
    "y_test = actual_pred_df.iloc[:,:].values\n",
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_acc1 = df1.iloc[:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.737531017369727"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc1 = accuracy_score(y_test, overall_acc1)\n",
    "acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7366625310173698"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_acc2 = df2.iloc[:, :].values\n",
    "\n",
    "acc2 = accuracy_score(y_test, overall_acc2)\n",
    "acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7749379652605459"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_acc3 = df3.iloc[:, :].values\n",
    "\n",
    "acc3 = accuracy_score(y_test, overall_acc3)\n",
    "acc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8023573200992555"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_acc4 = df4.iloc[:, :].values\n",
    "\n",
    "acc4 = accuracy_score(y_test, overall_acc4)\n",
    "acc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.736848635235732"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_acc5 = df5.iloc[:, :].values\n",
    "\n",
    "acc5 = accuracy_score(y_test, overall_acc5)\n",
    "acc5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
